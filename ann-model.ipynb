{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7504097,"sourceType":"datasetVersion","datasetId":4369957}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-17T19:07:55.248111Z","iopub.execute_input":"2024-09-17T19:07:55.249184Z","iopub.status.idle":"2024-09-17T19:07:55.648849Z","shell.execute_reply.started":"2024-09-17T19:07:55.249108Z","shell.execute_reply":"2024-09-17T19:07:55.647677Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/sample/perceptron_sampledata.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as f","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:07:55.651433Z","iopub.execute_input":"2024-09-17T19:07:55.651873Z","iopub.status.idle":"2024-09-17T19:07:59.196942Z","shell.execute_reply.started":"2024-09-17T19:07:55.651840Z","shell.execute_reply":"2024-09-17T19:07:59.195684Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/sample/perceptron_sampledata.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:07:59.204104Z","iopub.execute_input":"2024-09-17T19:07:59.208285Z","iopub.status.idle":"2024-09-17T19:07:59.265929Z","shell.execute_reply.started":"2024-09-17T19:07:59.208223Z","shell.execute_reply":"2024-09-17T19:07:59.263978Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"     x1    x2  label\n0  0.77 -1.14      0\n1 -0.33  1.44      0\n2  0.91 -3.07      0\n3 -0.37 -1.91      0\n4 -0.63 -1.53      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>x2</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.77</td>\n      <td>-1.14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.33</td>\n      <td>1.44</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.91</td>\n      <td>-3.07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.37</td>\n      <td>-1.91</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.63</td>\n      <td>-1.53</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y = df['label'].values\nx = df.drop(columns=['label'],axis=1).values","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:07:59.267788Z","iopub.execute_input":"2024-09-17T19:07:59.268698Z","iopub.status.idle":"2024-09-17T19:07:59.287392Z","shell.execute_reply.started":"2024-09-17T19:07:59.268655Z","shell.execute_reply":"2024-09-17T19:07:59.284933Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:07:59.294089Z","iopub.execute_input":"2024-09-17T19:07:59.295378Z","iopub.status.idle":"2024-09-17T19:08:00.409885Z","shell.execute_reply.started":"2024-09-17T19:07:59.295331Z","shell.execute_reply":"2024-09-17T19:08:00.408662Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"X_train = torch.FloatTensor(X_train)\nX_test = torch.FloatTensor(X_test)\ny_train = torch.FloatTensor(y_train)\ny_test = torch.FloatTensor(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.411918Z","iopub.execute_input":"2024-09-17T19:08:00.412665Z","iopub.status.idle":"2024-09-17T19:08:00.452173Z","shell.execute_reply.started":"2024-09-17T19:08:00.412620Z","shell.execute_reply":"2024-09-17T19:08:00.450985Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ANN_Model(nn.Module):\n    def __init__(self,input_features=2,hidden1=1,hidden2=2,out_features=1):\n        super().__init__()\n        self.layer1 = nn.Linear(input_features,hidden1)\n        self.layer2 = nn.Linear(hidden1,hidden2)\n        self.out = nn.Linear(hidden2,out_features)\n    \n    def forward(self,x):\n        x=f.tanh(self.layer1(x))\n        x=f.tanh(self.layer2(x))\n        x =self.out(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.453765Z","iopub.execute_input":"2024-09-17T19:08:00.454243Z","iopub.status.idle":"2024-09-17T19:08:00.463063Z","shell.execute_reply.started":"2024-09-17T19:08:00.454202Z","shell.execute_reply":"2024-09-17T19:08:00.461802Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(3)\nmodel = ANN_Model().to('cpu')\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.465024Z","iopub.execute_input":"2024-09-17T19:08:00.465701Z","iopub.status.idle":"2024-09-17T19:08:00.498780Z","shell.execute_reply.started":"2024-09-17T19:08:00.465658Z","shell.execute_reply":"2024-09-17T19:08:00.497614Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ANN_Model(\n  (layer1): Linear(in_features=2, out_features=1, bias=True)\n  (layer2): Linear(in_features=1, out_features=2, bias=True)\n  (out): Linear(in_features=2, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model.parameters()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.500479Z","iopub.execute_input":"2024-09-17T19:08:00.500911Z","iopub.status.idle":"2024-09-17T19:08:00.509195Z","shell.execute_reply.started":"2024-09-17T19:08:00.500870Z","shell.execute_reply":"2024-09-17T19:08:00.508027Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<generator object Module.parameters at 0x7ebcaf4dda10>"},"metadata":{}}]},{"cell_type":"code","source":"#Backward Propagation\nloss_function = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(params = model.parameters(),lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.510862Z","iopub.execute_input":"2024-09-17T19:08:00.511288Z","iopub.status.idle":"2024-09-17T19:08:00.520344Z","shell.execute_reply.started":"2024-09-17T19:08:00.511250Z","shell.execute_reply":"2024-09-17T19:08:00.519042Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"epochs = 200\nfinal_losses = []\nfor i in range(epochs):\n    model.train()\n    y_pred = model(X_train).squeeze()\n    loss = loss_function(y_pred,y_train)\n    final_losses.append(loss.item())\n    print(\"Epoch:{} and the loss: {}\".format(i,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.521788Z","iopub.execute_input":"2024-09-17T19:08:00.522381Z","iopub.status.idle":"2024-09-17T19:08:00.754363Z","shell.execute_reply.started":"2024-09-17T19:08:00.522338Z","shell.execute_reply":"2024-09-17T19:08:00.753072Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch:0 and the loss: 20.97280502319336\nEpoch:1 and the loss: 20.84825325012207\nEpoch:2 and the loss: 20.720531463623047\nEpoch:3 and the loss: 20.589962005615234\nEpoch:4 and the loss: 20.45701026916504\nEpoch:5 and the loss: 20.32225799560547\nEpoch:6 and the loss: 20.18640899658203\nEpoch:7 and the loss: 20.050228118896484\nEpoch:8 and the loss: 19.914527893066406\nEpoch:9 and the loss: 19.780128479003906\nEpoch:10 and the loss: 19.647815704345703\nEpoch:11 and the loss: 19.518314361572266\nEpoch:12 and the loss: 19.39226531982422\nEpoch:13 and the loss: 19.270214080810547\nEpoch:14 and the loss: 19.152591705322266\nEpoch:15 and the loss: 19.039714813232422\nEpoch:16 and the loss: 18.931804656982422\nEpoch:17 and the loss: 18.828968048095703\nEpoch:18 and the loss: 18.73124122619629\nEpoch:19 and the loss: 18.63858413696289\nEpoch:20 and the loss: 18.55089569091797\nEpoch:21 and the loss: 18.46803855895996\nEpoch:22 and the loss: 18.389833450317383\nEpoch:23 and the loss: 18.316082000732422\nEpoch:24 and the loss: 18.24656867980957\nEpoch:25 and the loss: 18.181072235107422\nEpoch:26 and the loss: 18.119369506835938\nEpoch:27 and the loss: 18.061237335205078\nEpoch:28 and the loss: 18.006454467773438\nEpoch:29 and the loss: 17.954818725585938\nEpoch:30 and the loss: 17.9061222076416\nEpoch:31 and the loss: 17.860179901123047\nEpoch:32 and the loss: 17.816810607910156\nEpoch:33 and the loss: 17.775836944580078\nEpoch:34 and the loss: 17.737110137939453\nEpoch:35 and the loss: 17.700477600097656\nEpoch:36 and the loss: 17.665794372558594\nEpoch:37 and the loss: 17.632938385009766\nEpoch:38 and the loss: 17.601787567138672\nEpoch:39 and the loss: 17.57223129272461\nEpoch:40 and the loss: 17.544164657592773\nEpoch:41 and the loss: 17.51749038696289\nEpoch:42 and the loss: 17.49212074279785\nEpoch:43 and the loss: 17.467971801757812\nEpoch:44 and the loss: 17.444969177246094\nEpoch:45 and the loss: 17.423038482666016\nEpoch:46 and the loss: 17.402118682861328\nEpoch:47 and the loss: 17.38214111328125\nEpoch:48 and the loss: 17.36305809020996\nEpoch:49 and the loss: 17.344810485839844\nEpoch:50 and the loss: 17.327350616455078\nEpoch:51 and the loss: 17.31063461303711\nEpoch:52 and the loss: 17.294612884521484\nEpoch:53 and the loss: 17.279254913330078\nEpoch:54 and the loss: 17.264522552490234\nEpoch:55 and the loss: 17.25037384033203\nEpoch:56 and the loss: 17.236785888671875\nEpoch:57 and the loss: 17.223724365234375\nEpoch:58 and the loss: 17.21115493774414\nEpoch:59 and the loss: 17.199068069458008\nEpoch:60 and the loss: 17.187423706054688\nEpoch:61 and the loss: 17.17620849609375\nEpoch:62 and the loss: 17.165393829345703\nEpoch:63 and the loss: 17.154964447021484\nEpoch:64 and the loss: 17.144901275634766\nEpoch:65 and the loss: 17.13518524169922\nEpoch:66 and the loss: 17.125795364379883\nEpoch:67 and the loss: 17.11672592163086\nEpoch:68 and the loss: 17.107954025268555\nEpoch:69 and the loss: 17.099470138549805\nEpoch:70 and the loss: 17.091259002685547\nEpoch:71 and the loss: 17.083309173583984\nEpoch:72 and the loss: 17.075607299804688\nEpoch:73 and the loss: 17.068143844604492\nEpoch:74 and the loss: 17.060909271240234\nEpoch:75 and the loss: 17.053892135620117\nEpoch:76 and the loss: 17.04708480834961\nEpoch:77 and the loss: 17.040477752685547\nEpoch:78 and the loss: 17.034061431884766\nEpoch:79 and the loss: 17.027828216552734\nEpoch:80 and the loss: 17.021774291992188\nEpoch:81 and the loss: 17.015888214111328\nEpoch:82 and the loss: 17.01016616821289\nEpoch:83 and the loss: 17.00459861755371\nEpoch:84 and the loss: 16.999183654785156\nEpoch:85 and the loss: 16.993911743164062\nEpoch:86 and the loss: 16.98877716064453\nEpoch:87 and the loss: 16.983779907226562\nEpoch:88 and the loss: 16.978912353515625\nEpoch:89 and the loss: 16.974163055419922\nEpoch:90 and the loss: 16.96953773498535\nEpoch:91 and the loss: 16.965028762817383\nEpoch:92 and the loss: 16.960628509521484\nEpoch:93 and the loss: 16.956336975097656\nEpoch:94 and the loss: 16.952146530151367\nEpoch:95 and the loss: 16.94805908203125\nEpoch:96 and the loss: 16.944067001342773\nEpoch:97 and the loss: 16.940166473388672\nEpoch:98 and the loss: 16.936359405517578\nEpoch:99 and the loss: 16.932640075683594\nEpoch:100 and the loss: 16.92900276184082\nEpoch:101 and the loss: 16.925447463989258\nEpoch:102 and the loss: 16.921972274780273\nEpoch:103 and the loss: 16.9185733795166\nEpoch:104 and the loss: 16.915245056152344\nEpoch:105 and the loss: 16.9119930267334\nEpoch:106 and the loss: 16.908809661865234\nEpoch:107 and the loss: 16.90569305419922\nEpoch:108 and the loss: 16.90264129638672\nEpoch:109 and the loss: 16.8996524810791\nEpoch:110 and the loss: 16.896724700927734\nEpoch:111 and the loss: 16.89385986328125\nEpoch:112 and the loss: 16.89105224609375\nEpoch:113 and the loss: 16.888296127319336\nEpoch:114 and the loss: 16.88559913635254\nEpoch:115 and the loss: 16.88295555114746\nEpoch:116 and the loss: 16.880361557006836\nEpoch:117 and the loss: 16.87781524658203\nEpoch:118 and the loss: 16.875322341918945\nEpoch:119 and the loss: 16.872875213623047\nEpoch:120 and the loss: 16.870473861694336\nEpoch:121 and the loss: 16.868114471435547\nEpoch:122 and the loss: 16.865802764892578\nEpoch:123 and the loss: 16.86353302001953\nEpoch:124 and the loss: 16.861303329467773\nEpoch:125 and the loss: 16.859113693237305\nEpoch:126 and the loss: 16.856964111328125\nEpoch:127 and the loss: 16.85485076904297\nEpoch:128 and the loss: 16.852779388427734\nEpoch:129 and the loss: 16.850738525390625\nEpoch:130 and the loss: 16.848735809326172\nEpoch:131 and the loss: 16.846769332885742\nEpoch:132 and the loss: 16.844833374023438\nEpoch:133 and the loss: 16.84292984008789\nEpoch:134 and the loss: 16.841060638427734\nEpoch:135 and the loss: 16.839221954345703\nEpoch:136 and the loss: 16.837413787841797\nEpoch:137 and the loss: 16.835634231567383\nEpoch:138 and the loss: 16.83388328552246\nEpoch:139 and the loss: 16.83216094970703\nEpoch:140 and the loss: 16.83046531677246\nEpoch:141 and the loss: 16.828800201416016\nEpoch:142 and the loss: 16.827159881591797\nEpoch:143 and the loss: 16.825544357299805\nEpoch:144 and the loss: 16.823955535888672\nEpoch:145 and the loss: 16.822391510009766\nEpoch:146 and the loss: 16.820846557617188\nEpoch:147 and the loss: 16.819332122802734\nEpoch:148 and the loss: 16.81783676147461\nEpoch:149 and the loss: 16.816364288330078\nEpoch:150 and the loss: 16.81491470336914\nEpoch:151 and the loss: 16.81348419189453\nEpoch:152 and the loss: 16.81207847595215\nEpoch:153 and the loss: 16.810691833496094\nEpoch:154 and the loss: 16.809326171875\nEpoch:155 and the loss: 16.80797576904297\nEpoch:156 and the loss: 16.806650161743164\nEpoch:157 and the loss: 16.805339813232422\nEpoch:158 and the loss: 16.80405044555664\nEpoch:159 and the loss: 16.802780151367188\nEpoch:160 and the loss: 16.801525115966797\nEpoch:161 and the loss: 16.8002872467041\nEpoch:162 and the loss: 16.7990665435791\nEpoch:163 and the loss: 16.797863006591797\nEpoch:164 and the loss: 16.796676635742188\nEpoch:165 and the loss: 16.79550552368164\nEpoch:166 and the loss: 16.79435157775879\nEpoch:167 and the loss: 16.793212890625\nEpoch:168 and the loss: 16.79208755493164\nEpoch:169 and the loss: 16.790977478027344\nEpoch:170 and the loss: 16.789884567260742\nEpoch:171 and the loss: 16.788803100585938\nEpoch:172 and the loss: 16.787736892700195\nEpoch:173 and the loss: 16.786684036254883\nEpoch:174 and the loss: 16.78564453125\nEpoch:175 and the loss: 16.784618377685547\nEpoch:176 and the loss: 16.783607482910156\nEpoch:177 and the loss: 16.782604217529297\nEpoch:178 and the loss: 16.781618118286133\nEpoch:179 and the loss: 16.780643463134766\nEpoch:180 and the loss: 16.779680252075195\nEpoch:181 and the loss: 16.778728485107422\nEpoch:182 and the loss: 16.777786254882812\nEpoch:183 and the loss: 16.776859283447266\nEpoch:184 and the loss: 16.775941848754883\nEpoch:185 and the loss: 16.775035858154297\nEpoch:186 and the loss: 16.774141311645508\nEpoch:187 and the loss: 16.77325439453125\nEpoch:188 and the loss: 16.772380828857422\nEpoch:189 and the loss: 16.77151870727539\nEpoch:190 and the loss: 16.77066421508789\nEpoch:191 and the loss: 16.769819259643555\nEpoch:192 and the loss: 16.768985748291016\nEpoch:193 and the loss: 16.76816177368164\nEpoch:194 and the loss: 16.767345428466797\nEpoch:195 and the loss: 16.76654052734375\nEpoch:196 and the loss: 16.765743255615234\nEpoch:197 and the loss: 16.764957427978516\nEpoch:198 and the loss: 16.764177322387695\nEpoch:199 and the loss: 16.76340675354004\n","output_type":"stream"}]},{"cell_type":"code","source":"def accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item()\n    acc = (correct/len(y_pred))*100\n    return acc","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.755590Z","iopub.execute_input":"2024-09-17T19:08:00.756018Z","iopub.status.idle":"2024-09-17T19:08:00.761991Z","shell.execute_reply.started":"2024-09-17T19:08:00.755979Z","shell.execute_reply":"2024-09-17T19:08:00.760687Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.inference_mode():\n    # forward pass\n    test_logits = model(X_test).squeeze()\n    test_pred = torch.round(torch.sigmoid(test_logits))\n    test_loss = loss_function(test_logits,y_test)\n    test_cc = accuracy_fn(y_true=y_test,y_pred=test_pred)\nprint(test_cc)","metadata":{"execution":{"iopub.status.busy":"2024-09-17T19:08:00.763387Z","iopub.execute_input":"2024-09-17T19:08:00.763782Z","iopub.status.idle":"2024-09-17T19:08:00.781251Z","shell.execute_reply.started":"2024-09-17T19:08:00.763745Z","shell.execute_reply":"2024-09-17T19:08:00.779708Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"75.0\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}